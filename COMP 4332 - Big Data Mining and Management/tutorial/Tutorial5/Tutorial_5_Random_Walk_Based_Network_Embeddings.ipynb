{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjpF-16Fj36w",
        "outputId": "89818c04-dac5-4789-b8f7-b68494d285df"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\chuny\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\chuny\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8jsaS_vjyo8",
        "outputId": "85ebb664-ce17-42b0-b17e-232f96d79bc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: networkx in c:\\users\\chuny\\anaconda3\\envs\\comp4332\\lib\\site-packages (3.4.2)\n",
            "Requirement already satisfied: gensim in c:\\users\\chuny\\anaconda3\\envs\\comp4332\\lib\\site-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\chuny\\anaconda3\\envs\\comp4332\\lib\\site-packages (from gensim) (1.26.3)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\chuny\\anaconda3\\envs\\comp4332\\lib\\site-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\chuny\\anaconda3\\envs\\comp4332\\lib\\site-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in c:\\users\\chuny\\anaconda3\\envs\\comp4332\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install networkx gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8xK1Yy-3jyo-"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "from itertools import chain\n",
        "from collections import defaultdict\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import roc_auc_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XElpxE_Xjyo_"
      },
      "source": [
        "# Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGUKIzj8jyo_"
      },
      "source": [
        "### Data Loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msET9jXajypA"
      },
      "source": [
        "We need to load networks into memory. Usually networks are organized as pairs of nodes. And sometimes different edges have different weights. Hence, we use networkx.DiGraph to store such structure information and attributes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GmtNm9aijypA"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def load_data(file_name):\n",
        "    \"\"\"\n",
        "    read edges from an edge file\n",
        "    \"\"\"\n",
        "    edges = list()\n",
        "    df = pd.read_csv(file_name)\n",
        "    for idx, row in df.iterrows():\n",
        "        user_id, friends = row[\"user_id\"], eval(row[\"friends\"])\n",
        "        for friend in friends:\n",
        "            # add each friend relation as an edge\n",
        "            ########## begin ##########\n",
        "            edges.append((user_id, friend))\n",
        "            ########## end ##########\n",
        "    edges = sorted(edges)\n",
        "\n",
        "    return edges\n",
        "\n",
        "def generate_false_edges(true_edges, num_false_edges=5):\n",
        "    \"\"\"\n",
        "    generate false edges given true edges\n",
        "    \"\"\"\n",
        "    nodes = list(set(chain.from_iterable(true_edges)))\n",
        "    true_edges = set(true_edges)\n",
        "    false_edges = set()\n",
        "    while len(false_edges) < num_false_edges:\n",
        "        # randomly sample two different nodes and check whether the pair exisit or not\n",
        "        # check 3 things:\n",
        "        #   if head == tail, then it is not an edge.\n",
        "        #   if the edge is in true_edges, skip.\n",
        "        #   if the edge is in false edges, skip.\n",
        "        ########## begin ##########\n",
        "        head = random.choice(nodes)\n",
        "        tail = random.choice(nodes)\n",
        "        if head != tail and (head, tail) not in true_edges and (head, tail) not in false_edges:\n",
        "            false_edges.add((head, tail))\n",
        "        ########## end ##########\n",
        "\n",
        "    false_edges = sorted(false_edges)\n",
        "    return false_edges\n",
        "\n",
        "def construct_graph_from_edges(edges):\n",
        "    \"\"\"\n",
        "    generate a directed graph object given true edges\n",
        "    DiGraph documentation: https://networkx.github.io/documentation/stable/reference/classes/digraph.html\n",
        "    \"\"\"\n",
        "    # convert a list of edges {(u, v)} to a list of edges with weights {(u, v, w)}\n",
        "    edge_weight = defaultdict(float)\n",
        "\n",
        "    ########## begin ##########\n",
        "    # 1. For each edge, add 1.0 to the edge_weight\n",
        "\n",
        "    for edge in edges:\n",
        "        edge_weight[edge] += 1.0\n",
        "\n",
        "    ###########################\n",
        "    # 2. In a sorted order of edges, make a list of weighted_edge_list and weight_list.\n",
        "    #   - weighted_edge_list: list[tuple], with each element having a format (node_1, node_2, weight)\n",
        "    #   - weight_list: list[int]\n",
        "    weighted_edge_list = list()\n",
        "    weight_list = []\n",
        "\n",
        "    for edge in sorted(edge_weight.keys()):\n",
        "        weight = edge_weight[edge]\n",
        "        weighted_edge_list.append((edge[0], edge[1], weight))\n",
        "        weight_list.append(weight)\n",
        "\n",
        "    ########## end ##########\n",
        "\n",
        "    weights = np.asarray(weight_list)\n",
        "    print(f\"edges have mean weights {weights.mean()} with std {weights.std()}\")\n",
        "    graph = nx.DiGraph()\n",
        "    graph.add_weighted_edges_from(weighted_edge_list)\n",
        "\n",
        "    print(\"number of nodes:\", graph.number_of_nodes())\n",
        "    print(\"number of edges:\", graph.number_of_edges())\n",
        "\n",
        "    return graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGUxcMjxjypA"
      },
      "source": [
        "### Random Walk Generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFObcIl8jypA"
      },
      "source": [
        "Random walk generators or random walkers yield random walks that contain both local and higher-order neighborhood information. However, naive non-uniform sampling is very slow, which requires O(n) time complexity. Here alias sampling can reduce the time complexity to O(1) with O(n) space. If you are interested, please see the following blog."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "14OAQF0ejypB"
      },
      "outputs": [],
      "source": [
        "def alias_setup(probs):\n",
        "    \"\"\"\n",
        "    compute utility lists for non-uniform sampling from discrete distributions.\n",
        "    details: https://lips.cs.princeton.edu/the-alias-method-efficient-sampling-with-many-discrete-outcomes/\n",
        "    \"\"\"\n",
        "    K = len(probs)\n",
        "    q = np.zeros(K)\n",
        "    J = np.zeros(K, dtype=int)\n",
        "\n",
        "    smaller = list()\n",
        "    larger = list()\n",
        "    for kk, prob in enumerate(probs):\n",
        "        q[kk] = K * prob\n",
        "        if q[kk] < 1.0:\n",
        "            smaller.append(kk)\n",
        "        else:\n",
        "            larger.append(kk)\n",
        "\n",
        "    while len(smaller) > 0 and len(larger) > 0:\n",
        "        small = smaller.pop()\n",
        "        large = larger.pop()\n",
        "\n",
        "        J[small] = large\n",
        "        q[large] = q[large] + q[small] - 1.0\n",
        "        if q[large] < 1.0:\n",
        "            smaller.append(large)\n",
        "        else:\n",
        "            larger.append(large)\n",
        "\n",
        "    return J, q\n",
        "\n",
        "def get_alias_node(graph, node):\n",
        "    \"\"\"\n",
        "    get the alias node setup lists for a given node.\n",
        "    \"\"\"\n",
        "    # get the unnormalized probabilities with the first-order information\n",
        "    unnormalized_probs = list()\n",
        "\n",
        "    ########## begin ##########\n",
        "    for nbr in graph.neighbors(node):\n",
        "        unnormalized_probs.append(graph[node][nbr]['weight'])\n",
        "    ########## end ##########\n",
        "\n",
        "    unnormalized_probs = np.array(unnormalized_probs)\n",
        "    if len(unnormalized_probs) > 0:\n",
        "        normalized_probs = unnormalized_probs / unnormalized_probs.sum()\n",
        "    else:\n",
        "        normalized_probs = unnormalized_probs\n",
        "\n",
        "    return alias_setup(normalized_probs)\n",
        "\n",
        "def get_alias_edge(graph, src, dst, p=1, q=1):\n",
        "    \"\"\"\n",
        "    get the alias edge setup lists for a given edge.\n",
        "    \"\"\"\n",
        "    # get the unnormalized probabilities with the second-order information\n",
        "    unnormalized_probs = list()\n",
        "\n",
        "    ########## begin ##########\n",
        "    for dst_nbr in graph.neighbors(dst):\n",
        "        if dst_nbr == src: # distance is 0\n",
        "            unnormalized_probs.append(graph[dst][dst_nbr]['weight'] / p)\n",
        "        elif graph.has_edge(dst_nbr, src): # distance is 1\n",
        "            unnormalized_probs.append(graph[dst][dst_nbr]['weight'])\n",
        "        else: # distance is 2\n",
        "            unnormalized_probs.append(graph[dst][dst_nbr]['weight'] / q)\n",
        "    ########## end ##########\n",
        "\n",
        "\n",
        "    unnormalized_probs = np.array(unnormalized_probs)\n",
        "    if len(unnormalized_probs) > 0:\n",
        "        normalized_probs = unnormalized_probs / unnormalized_probs.sum()\n",
        "    else:\n",
        "        normalized_probs = unnormalized_probs\n",
        "\n",
        "    return alias_setup(normalized_probs)\n",
        "\n",
        "def preprocess_transition_probs(graph, p=1, q=1):\n",
        "    \"\"\"\n",
        "    preprocess transition probabilities for guiding the random walks.\n",
        "    \"\"\"\n",
        "    alias_nodes = dict()\n",
        "    for node in graph.nodes():\n",
        "        alias_nodes[node] = get_alias_node(graph, node)\n",
        "\n",
        "    alias_edges = dict()\n",
        "    for edge in graph.edges():\n",
        "        alias_edges[edge] = get_alias_edge(graph, edge[0], edge[1], p=p, q=q)\n",
        "\n",
        "    return alias_nodes, alias_edges"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kl_3KVU0jypB"
      },
      "source": [
        "The difference between DeepWalk and node2vec is how to generate random walks. The former only consider the first-order information while the latter also involves the second-order information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LZLURa6GjypB"
      },
      "outputs": [],
      "source": [
        "def alias_draw(J, q):\n",
        "    \"\"\"\n",
        "    draw sample from a non-uniform discrete distribution using alias sampling.\n",
        "    \"\"\"\n",
        "    K = len(J)\n",
        "\n",
        "    kk = int(np.floor(np.random.rand() * K))\n",
        "    if np.random.rand() < q[kk]:\n",
        "        return kk\n",
        "    else:\n",
        "        return J[kk]\n",
        "\n",
        "\n",
        "# helper function to generate the long random walk as desired\n",
        "def fallback(walk, fetch_last_num=1):\n",
        "    if len(walk) > fetch_last_num:\n",
        "        walk.pop()\n",
        "        fetched = []\n",
        "        for i in range(fetch_last_num):\n",
        "            fetched.append(walk[-1-i])\n",
        "        return walk, fetched\n",
        "    else:\n",
        "        return [], [None for _ in range(fetch_last_num)]\n",
        "\n",
        "def generate_first_order_random_walk(graph, alias_nodes,\n",
        "                                     walk_length=10, start_node=None, verbose=False, max_trails=10):\n",
        "    \"\"\"\n",
        "    simulate a random walk starting from start node and considering the first order information.\n",
        "    max_trials: set the max trials to be one for standard random walk. Larger max_trails will make the generated biased.\n",
        "    \"\"\"\n",
        "    if start_node == None:\n",
        "        start_node = np.random.choice(graph.nodes())\n",
        "    walk = [start_node]\n",
        "    cur = start_node\n",
        "    num_tried = 0\n",
        "\n",
        "    ########## begin ##########\n",
        "    while len(walk) < walk_length:\n",
        "        cur_nbrs = list(graph.neighbors(cur))\n",
        "        if len(cur_nbrs) > 0: # if we can sample next nodes\n",
        "            # sample the next node based on alias_nodes\n",
        "            cur = cur_nbrs[alias_draw(*alias_nodes[cur])]\n",
        "            walk.append(cur)\n",
        "        else: # if we can't do that\n",
        "            num_tried += 1\n",
        "            if num_tried >= max_trails:\n",
        "                break\n",
        "\n",
        "            walk, fetched = fallback(walk, fetch_last_num=1)\n",
        "            cur = fetched[0]\n",
        "            if len(walk) == 0: # if falls back to the empty walk\n",
        "                start_node = np.random.choice(graph.nodes())\n",
        "                walk = [start_node]\n",
        "                cur = start_node\n",
        "    ########## end ##########\n",
        "\n",
        "    if verbose:\n",
        "        print(f'walk of lenght {len(walk)} generated with {num_tried} trails')\n",
        "    return walk\n",
        "\n",
        "def generate_second_order_random_walk(graph, alias_nodes, alias_edges,\n",
        "                                      walk_length=10, start_node=None, verbose=False, max_trails=10):\n",
        "    \"\"\"\n",
        "    simulate a random walk starting from start node and considering the second order information.\n",
        "    \"\"\"\n",
        "    if start_node == None:\n",
        "        start_node = np.random.choice(graph.nodes())\n",
        "    walk = [start_node]\n",
        "\n",
        "    prev = None\n",
        "    cur = start_node\n",
        "    num_tried = 0\n",
        "\n",
        "    ########## begin ##########\n",
        "    while len(walk) < walk_length:\n",
        "        cur_nbrs = list(graph.neighbors(cur))\n",
        "        if len(cur_nbrs) > 0:\n",
        "            if prev is None:\n",
        "                # sample the next node based on alias_nodes\n",
        "                cur = cur_nbrs[alias_draw(*alias_nodes[cur])]\n",
        "            else:\n",
        "                # sample the next node based on alias_edges\n",
        "                cur = cur_nbrs[alias_draw(*alias_edges[(prev, cur)])]\n",
        "            walk.append(cur)\n",
        "            prev = walk[-2]\n",
        "        else:\n",
        "            num_tried += 1\n",
        "            if num_tried >= max_trails:\n",
        "                break\n",
        "            walk, (cur, prev) = fallback(walk, fetch_last_num=2)\n",
        "            if len(walk) == 0:\n",
        "                start_node = np.random.choice(graph.nodes())\n",
        "                walk = [start_node]\n",
        "                cur = start_node\n",
        "                prev = None\n",
        "    ########## end ##########\n",
        "    if verbose:\n",
        "        print(f'walk of lenght {len(walk)} generated with {num_tried} trails')\n",
        "    return walk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-E0ek0rjypB"
      },
      "source": [
        "### Network Embedding Algorithms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vNKaKwPVjypC"
      },
      "outputs": [],
      "source": [
        "def build_deepwalk(graph, alias_nodes, node_dim=10, num_walks=10, walk_length=10, negative=10):\n",
        "    \"\"\"\n",
        "    build a deepwalk model\n",
        "    \"\"\"\n",
        "    print(\"building a DeepWalk model...\", end=\"\\t\")\n",
        "    st = time.time()\n",
        "    np.random.seed(0)\n",
        "    nodes = list(graph.nodes())\n",
        "    walks = list()\n",
        "    # generate random walks\n",
        "    for walk_iter in range(num_walks):\n",
        "        np.random.shuffle(nodes)\n",
        "        for node in nodes:\n",
        "            walks.append(generate_first_order_random_walk(graph, alias_nodes,\n",
        "                                                          walk_length=walk_length, start_node=node))\n",
        "\n",
        "    walk_lens = [len(w) for w in walks]\n",
        "    if len(walk_lens) > 0:\n",
        "        avg_walk_len = sum(walk_lens) / len(walk_lens)\n",
        "    else:\n",
        "        avg_walk_len = 0.0\n",
        "    print(\"number of walks: %d\\taverage walk length: %.4f\" % (len(walks), avg_walk_len), end=\"\\t\")\n",
        "\n",
        "    # train a skip-gram model for these walks\n",
        "    model = Word2Vec(walks, vector_size=node_dim, window=3, min_count=0, sg=1, negative=negative, workers=os.cpu_count(), epochs=10)\n",
        "    print(\"build time: %.4f\" % (time.time()-st))\n",
        "\n",
        "    return model\n",
        "\n",
        "def build_node2vec(graph, alias_nodes, alias_edges, node_dim=10, num_walks=10, walk_length=10, negative=10):\n",
        "    \"\"\"\n",
        "    build a node2vec model\n",
        "    \"\"\"\n",
        "    print(\"building a node2vec model...\", end=\"\\t\")\n",
        "    st = time.time()\n",
        "    np.random.seed(0)\n",
        "    nodes = list(graph.nodes())\n",
        "    walks = list()\n",
        "    # generate random walks\n",
        "    for walk_iter in range(num_walks):\n",
        "        np.random.shuffle(nodes)\n",
        "        for node in nodes:\n",
        "            walks.append(generate_second_order_random_walk(graph, alias_nodes, alias_edges,\n",
        "                                                           walk_length=walk_length, start_node=node))\n",
        "\n",
        "    walk_lens = [len(w) for w in walks]\n",
        "    if len(walk_lens) > 0:\n",
        "        avg_walk_len = sum(walk_lens) / len(walk_lens)\n",
        "    else:\n",
        "        avg_walk_len = 0.0\n",
        "    print(\"number of walks: %d\\taverage walk length: %.4f\" % (len(walks), avg_walk_len), end=\"\\t\")\n",
        "\n",
        "    # train a skip-gram model for these walks\n",
        "    model = Word2Vec(walks, vector_size=node_dim, window=3, min_count=0, sg=1, negative=negative, workers=os.cpu_count(), epochs=10, seed=1)\n",
        "    print(\"build time: %.4f\" % (time.time()-st))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWP_-XYXjypC"
      },
      "source": [
        "### Scorer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ARiKU3dGjypC"
      },
      "outputs": [],
      "source": [
        "def get_cosine_sim(model, u, v):\n",
        "    \"\"\"\n",
        "    get the cosine similarity between two nodes\n",
        "    \"\"\"\n",
        "    try:\n",
        "        u = model.wv[u]\n",
        "        v = model.wv[v]\n",
        "        return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))\n",
        "    except:\n",
        "        return 0\n",
        "\n",
        "def get_auc_score(model, true_edges, false_edges):\n",
        "    \"\"\"\n",
        "    get the auc score\n",
        "    \"\"\"\n",
        "    y_true = [1] * len(true_edges) + [0] * len(false_edges)\n",
        "\n",
        "    y_score = list()\n",
        "    for e in true_edges:\n",
        "        y_score.append(get_cosine_sim(model, e[0], e[1]))\n",
        "    for e in false_edges:\n",
        "        y_score.append(get_cosine_sim(model, e[0], e[1]))\n",
        "\n",
        "    return roc_auc_score(y_true, y_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYXu9oMcjypC"
      },
      "source": [
        "### Try them over a Real-life Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TapvUELWjypC"
      },
      "source": [
        "Firstly, we need to load edges into memory and use the networkx.DiGraph structure to store the graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oz3_M1zcjypC",
        "outputId": "9c9a7c47-9cb1-457e-caf3-cf661ee8686e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "edges have mean weights 1.0 with std 0.0\n",
            "number of nodes: 3930\n",
            "number of edges: 15688\n"
          ]
        }
      ],
      "source": [
        "user_file = \"data/user.csv\"\n",
        "edges = load_data(user_file)\n",
        "graph = construct_graph_from_edges(edges)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q99QtPU-jypC"
      },
      "source": [
        "After that, we can use preprocess transition probabilities with the help of alias sampling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "VY985fUxjypC"
      },
      "outputs": [],
      "source": [
        "alias_nodes, alias_edges = preprocess_transition_probs(graph, p=2, q=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dcVuIVBjypD"
      },
      "source": [
        "We can use random walk generators to generate random walks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfjP9vvVjypD"
      },
      "source": [
        "Let's try to generate a first-order random walk and a second-order random walk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsAhfaRHjypD",
        "outputId": "881130aa-f900-444a-a0d1-56768048b8fc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['N6ZTMIue-2b30CJv2tyPGg',\n",
              " 'gqL5KBs2oS7qobnyd99iKg',\n",
              " 'zTK1nPD2Hpa-ksSXsE-JzQ',\n",
              " 'gqL5KBs2oS7qobnyd99iKg',\n",
              " 'AmMd7xpnaf8axS_roCBFRw',\n",
              " 'YBT3EKUNN4IP8m4x7sGu1g',\n",
              " 'AmMd7xpnaf8axS_roCBFRw',\n",
              " 'G-6X-llgA_qAxGxocykHzQ',\n",
              " 'AmMd7xpnaf8axS_roCBFRw',\n",
              " 'wUgRsMwL-BCreuMBgmFdWg']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate_first_order_random_walk(graph, alias_nodes=alias_nodes,\n",
        "                                 start_node=\"N6ZTMIue-2b30CJv2tyPGg\", walk_length=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQOvgcY9jypD",
        "outputId": "a50cdc2c-7961-4f4c-c630-caf2be20c2f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['N6ZTMIue-2b30CJv2tyPGg',\n",
              " 'gqL5KBs2oS7qobnyd99iKg',\n",
              " 'juLlBJ6SQMyMLxPLczZxNA',\n",
              " 'gqL5KBs2oS7qobnyd99iKg',\n",
              " 'zTK1nPD2Hpa-ksSXsE-JzQ',\n",
              " 'MQwSyZ2MZ6N7rtAmphZCow',\n",
              " 'ZZoxuBqon2tTMST4YBWa8w',\n",
              " 'ZljxRipwkMk9u3JXEi67iQ',\n",
              " 'el3TmKFEFzZOcNbCw2FNlQ',\n",
              " '3NnPbhmv_vEfPTBp2pnn9Q']"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate_second_order_random_walk(graph, alias_nodes=alias_nodes, alias_edges=alias_edges,\n",
        "                                  start_node=\"N6ZTMIue-2b30CJv2tyPGg\", walk_length=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXfI661ljypD"
      },
      "source": [
        "And we can build a DeepWalk model and a node2vec model. Here we set p=q=0.5 so that the walker will not go very far away from the start node."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RX3pLd0ZjypD",
        "outputId": "f78a06d7-4426-40a3-ca65-2ba2d60e154b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "building a DeepWalk model...\tnumber of walks: 39300\taverage walk length: 8.7485\tbuild time: 9.8894\n"
          ]
        }
      ],
      "source": [
        "deepwalk = build_deepwalk(graph, alias_nodes, node_dim=10, num_walks=10, walk_length=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6mpODqZjypD",
        "outputId": "1fe0e957-b436-4538-a3fe-34467eb0dbaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "building a node2vec model...\tnumber of walks: 39300\taverage walk length: 9.8997\tbuild time: 18.9038\n"
          ]
        }
      ],
      "source": [
        "node2vec = build_node2vec(graph, alias_nodes, alias_edges, node_dim=10, num_walks=10, walk_length=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbaqlzCOjypD"
      },
      "source": [
        "Let's see the node embeddings of three nodes, and cosine similarities of two edges."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCejAMhMjypD",
        "outputId": "16bbfcd3-ac73-43ae-a348-b3f690941e84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Deepwalk (1st order random walk) ---\n",
            "node embedding (\"N6ZTMIue-2b30CJv2tyPGg\"): [-0.10837889 -0.10652022  1.4146445   0.8012465   0.65344757 -0.14094147\n",
            "  0.7993037   0.68759024 -0.30896777 -0.82715493]\n",
            "node embedding (\"N7E-CfqdME28dakWdEKNvw\"): [-0.4287536   0.22108056  1.907664    0.22008018  1.1516143   0.24478206\n",
            "  1.3893412   1.2056402  -1.047422   -0.16928416]\n",
            "node embedding (\"MmlJSLDg-IFaeXb5wdJbgg\"): [ 0.6157956  -1.3259395   1.6965528   1.166923   -0.84236723  2.593628\n",
            "  1.9057      0.58812636 -2.002583    0.7257554 ]\n",
            "true edge (\"N6ZTMIue-2b30CJv2tyPGg\", \"N7E-CfqdME28dakWdEKNvw\"): 0.85878074\n",
            "false edge (\"N6ZTMIue-2b30CJv2tyPGg\", \"MmlJSLDg-IFaeXb5wdJbgg\"): 0.4199828\n",
            "\n",
            "--- Node2Vec (2nd order random walk) ---\n",
            "node embedding (\"N6ZTMIue-2b30CJv2tyPGg\"): [-0.21442583 -0.8520855   1.712711   -0.20094264 -0.89525235  0.9691995\n",
            "  0.93174154  0.43016255 -0.11394635 -0.02940412]\n",
            "node embedding (\"N7E-CfqdME28dakWdEKNvw\"): [ 0.18206334 -1.7999327   1.3429816   0.14228307 -1.0605571   1.2758462\n",
            "  1.086734    0.3744897  -0.2798071  -0.08060516]\n",
            "node embedding (\"MmlJSLDg-IFaeXb5wdJbgg\"): [ 3.4502368  -0.9514413   1.4829377  -0.08971468 -0.71561587  0.04114188\n",
            "  1.0661868   0.22154236  0.05129561 -1.9866679 ]\n",
            "true edge (\"N6ZTMIue-2b30CJv2tyPGg\", \"N7E-CfqdME28dakWdEKNvw\"): 0.91935444\n",
            "false edge (\"N6ZTMIue-2b30CJv2tyPGg\", \"MmlJSLDg-IFaeXb5wdJbgg\"): 0.3824284\n"
          ]
        }
      ],
      "source": [
        "print('--- Deepwalk (1st order random walk) ---')\n",
        "print(\"node embedding (\\\"N6ZTMIue-2b30CJv2tyPGg\\\"):\",\n",
        "      deepwalk.wv[\"N6ZTMIue-2b30CJv2tyPGg\"])\n",
        "print(\"node embedding (\\\"N7E-CfqdME28dakWdEKNvw\\\"):\",\n",
        "      deepwalk.wv[\"N7E-CfqdME28dakWdEKNvw\"])\n",
        "print(\"node embedding (\\\"MmlJSLDg-IFaeXb5wdJbgg\\\"):\",\n",
        "      deepwalk.wv[\"MmlJSLDg-IFaeXb5wdJbgg\"])\n",
        "print(\"true edge (\\\"N6ZTMIue-2b30CJv2tyPGg\\\", \\\"N7E-CfqdME28dakWdEKNvw\\\"):\",\n",
        "      get_cosine_sim(deepwalk, \"N6ZTMIue-2b30CJv2tyPGg\", \"N7E-CfqdME28dakWdEKNvw\"))\n",
        "print(\"false edge (\\\"N6ZTMIue-2b30CJv2tyPGg\\\", \\\"MmlJSLDg-IFaeXb5wdJbgg\\\"):\",\n",
        "      get_cosine_sim(deepwalk, \"N6ZTMIue-2b30CJv2tyPGg\", \"MmlJSLDg-IFaeXb5wdJbgg\"))\n",
        "\n",
        "print()\n",
        "print('--- Node2Vec (2nd order random walk) ---')\n",
        "print(\"node embedding (\\\"N6ZTMIue-2b30CJv2tyPGg\\\"):\",\n",
        "      node2vec.wv[\"N6ZTMIue-2b30CJv2tyPGg\"])\n",
        "print(\"node embedding (\\\"N7E-CfqdME28dakWdEKNvw\\\"):\",\n",
        "      node2vec.wv[\"N7E-CfqdME28dakWdEKNvw\"])\n",
        "print(\"node embedding (\\\"MmlJSLDg-IFaeXb5wdJbgg\\\"):\",\n",
        "      node2vec.wv[\"MmlJSLDg-IFaeXb5wdJbgg\"])\n",
        "print(\"true edge (\\\"N6ZTMIue-2b30CJv2tyPGg\\\", \\\"N7E-CfqdME28dakWdEKNvw\\\"):\",\n",
        "      get_cosine_sim(node2vec, \"N6ZTMIue-2b30CJv2tyPGg\", \"N7E-CfqdME28dakWdEKNvw\"))\n",
        "print(\"false edge (\\\"N6ZTMIue-2b30CJv2tyPGg\\\", \\\"MmlJSLDg-IFaeXb5wdJbgg\\\"):\",\n",
        "      get_cosine_sim(node2vec, \"N6ZTMIue-2b30CJv2tyPGg\", \"MmlJSLDg-IFaeXb5wdJbgg\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCAPdq_vjypD"
      },
      "source": [
        "By comparing the true edges and false edges similarity reported by Deepwalk and Node2Vec, we can see that Node2Vec is capable of embedding true edges with higher similarity, and false edges with lower similarity than Deepwalk, and therefore is considered as a better model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZ325bUYjypD"
      },
      "source": [
        "# Link Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KA3ICJw1jypE"
      },
      "source": [
        "Link prediction is a task to prediction unseen edges based on graph information. Let's use cross validation to check their performance in the link prediction task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "p3QVS_-PjypE"
      },
      "outputs": [],
      "source": [
        "def case(kfold=5, node_dim=10, num_walks=10, walk_length=5, p=0.5, q=0.5):\n",
        "    np.random.seed(0)\n",
        "\n",
        "    deepwalk_auc_scores = list()\n",
        "    node2vec_auc_scores = list()\n",
        "    kf = KFold(n_splits=kfold, shuffle=True)\n",
        "    for k, (train_idx, valid_idx) in enumerate(kf.split(edges)):\n",
        "        # split edges into training and validation\n",
        "        train_edges = [edges[idx] for idx in train_idx]\n",
        "        valid_edges = [edges[idx] for idx in valid_idx]\n",
        "        # generate the same validation size of false edges\n",
        "        false_edges = generate_false_edges(edges, num_false_edges=len(valid_edges))\n",
        "\n",
        "        # construct the graph and preprocess transition probabilities\n",
        "        graph = construct_graph_from_edges(train_edges)\n",
        "        alias_nodes, alias_edges = preprocess_transition_probs(graph, p=p, q=q)\n",
        "\n",
        "        # build models and get auc scores\n",
        "        model = build_deepwalk(graph, alias_nodes,\n",
        "                               node_dim=node_dim, num_walks=num_walks, walk_length=walk_length)\n",
        "        deepwalk_auc_scores.append(get_auc_score(model, valid_edges, false_edges))\n",
        "\n",
        "        model = build_node2vec(graph, alias_nodes, alias_edges,\n",
        "                               node_dim=node_dim, num_walks=num_walks, walk_length=walk_length)\n",
        "        node2vec_auc_scores.append(get_auc_score(model, valid_edges, false_edges))\n",
        "\n",
        "    deepwalk_auc_scores = np.array(deepwalk_auc_scores)\n",
        "    node2vec_auc_scores = np.array(node2vec_auc_scores)\n",
        "    print(\"DeepWalk: avg auc score: %.4f\\tstd: %.4f\" % (deepwalk_auc_scores.mean(), deepwalk_auc_scores.std()))\n",
        "    print(\"node2vec: avg auc score: %.4f\\tstd: %.4f\" % (node2vec_auc_scores.mean(), node2vec_auc_scores.std()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pRqVk4HjypE",
        "outputId": "8c7d042e-79db-4296-c506-a81be82d47b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "edges have mean weights 1.0 with std 0.0\n",
            "number of nodes: 3574\n",
            "number of edges: 12550\n",
            "building a DeepWalk model...\tnumber of walks: 7148\taverage walk length: 2.0000\tbuild time: 1.0755\n",
            "building a node2vec model...\tnumber of walks: 7148\taverage walk length: 2.0000\tbuild time: 1.0965\n",
            "edges have mean weights 1.0 with std 0.0\n",
            "number of nodes: 3610\n",
            "number of edges: 12550\n",
            "building a DeepWalk model...\tnumber of walks: 7220\taverage walk length: 2.0000\tbuild time: 1.1728\n",
            "building a node2vec model...\tnumber of walks: 7220\taverage walk length: 2.0000\tbuild time: 1.0512\n",
            "edges have mean weights 1.0 with std 0.0\n",
            "number of nodes: 3639\n",
            "number of edges: 12550\n",
            "building a DeepWalk model...\tnumber of walks: 7278\taverage walk length: 2.0000\tbuild time: 0.9987\n",
            "building a node2vec model...\tnumber of walks: 7278\taverage walk length: 2.0000\tbuild time: 1.0017\n",
            "edges have mean weights 1.0 with std 0.0\n",
            "number of nodes: 3582\n",
            "number of edges: 12551\n",
            "building a DeepWalk model...\tnumber of walks: 7164\taverage walk length: 2.0000\tbuild time: 1.0009\n",
            "building a node2vec model...\tnumber of walks: 7164\taverage walk length: 2.0000\tbuild time: 0.9937\n",
            "edges have mean weights 1.0 with std 0.0\n",
            "number of nodes: 3600\n",
            "number of edges: 12551\n",
            "building a DeepWalk model...\tnumber of walks: 7200\taverage walk length: 2.0000\tbuild time: 0.9545\n",
            "building a node2vec model...\tnumber of walks: 7200\taverage walk length: 2.0000\tbuild time: 0.9785\n",
            "DeepWalk: avg auc score: 0.5955\tstd: 0.0100\n",
            "node2vec: avg auc score: 0.5952\tstd: 0.0099\n"
          ]
        }
      ],
      "source": [
        "case(kfold=5, node_dim=2, num_walks=2, walk_length=2, p=0.5, q=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RW1u7ll8jypE",
        "outputId": "01f27a9d-ea22-4c71-e0c4-9c6df00d52b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "edges have mean weights 1.0 with std 0.0\n",
            "number of nodes: 3574\n",
            "number of edges: 12550\n",
            "building a DeepWalk model...\tnumber of walks: 17870\taverage walk length: 4.4799\tbuild time: 2.9830\n",
            "building a node2vec model...\tnumber of walks: 17870\taverage walk length: 4.9491\tbuild time: 6.9996\n",
            "edges have mean weights 1.0 with std 0.0\n",
            "number of nodes: 3610\n",
            "number of edges: 12550\n",
            "building a DeepWalk model...\tnumber of walks: 18050\taverage walk length: 4.5289\tbuild time: 2.9187\n",
            "building a node2vec model...\tnumber of walks: 18050\taverage walk length: 4.9625\tbuild time: 6.7321\n",
            "edges have mean weights 1.0 with std 0.0\n",
            "number of nodes: 3639\n",
            "number of edges: 12550\n",
            "building a DeepWalk model...\tnumber of walks: 18195\taverage walk length: 4.4843\tbuild time: 2.9843\n",
            "building a node2vec model...\tnumber of walks: 18195\taverage walk length: 4.9532\tbuild time: 7.2828\n",
            "edges have mean weights 1.0 with std 0.0\n",
            "number of nodes: 3582\n",
            "number of edges: 12551\n",
            "building a DeepWalk model...\tnumber of walks: 17910\taverage walk length: 4.4749\tbuild time: 2.8902\n",
            "building a node2vec model...\tnumber of walks: 17910\taverage walk length: 4.9658\tbuild time: 8.4077\n",
            "edges have mean weights 1.0 with std 0.0\n",
            "number of nodes: 3600\n",
            "number of edges: 12551\n",
            "building a DeepWalk model...\tnumber of walks: 18000\taverage walk length: 4.5000\tbuild time: 3.2258\n",
            "building a node2vec model...\tnumber of walks: 18000\taverage walk length: 4.9451\tbuild time: 7.0788\n",
            "DeepWalk: avg auc score: 0.7493\tstd: 0.0083\n",
            "node2vec: avg auc score: 0.7949\tstd: 0.0068\n"
          ]
        }
      ],
      "source": [
        "case(kfold=5, node_dim=5, num_walks=5, walk_length=5, p=0.5, q=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "wvflNFrNjypE",
        "outputId": "2659980d-d2c4-4f79-c307-5b4011c0cd68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "edges have mean weights 1.0 with std 0.0\n",
            "number of nodes: 3574\n",
            "number of edges: 12550\n",
            "building a DeepWalk model...\tnumber of walks: 35740\taverage walk length: 8.5227\tbuild time: 7.4978\n",
            "building a node2vec model...\tnumber of walks: 35740\taverage walk length: 9.7371\tbuild time: 15.8654\n",
            "edges have mean weights 1.0 with std 0.0\n",
            "number of nodes: 3610\n",
            "number of edges: 12550\n",
            "building a DeepWalk model...\tnumber of walks: 36100\taverage walk length: 8.6765\tbuild time: 7.5365\n",
            "building a node2vec model...\tnumber of walks: 36100\taverage walk length: 9.8225\tbuild time: 42.9511\n",
            "edges have mean weights 1.0 with std 0.0\n",
            "number of nodes: 3639\n",
            "number of edges: 12550\n",
            "building a DeepWalk model...\tnumber of walks: 36390\taverage walk length: 8.5785\tbuild time: 10.0851\n",
            "building a node2vec model...\tnumber of walks: 36390\taverage walk length: 9.7888\tbuild time: 42.4838\n",
            "edges have mean weights 1.0 with std 0.0\n",
            "number of nodes: 3582\n",
            "number of edges: 12551\n",
            "building a DeepWalk model...\tnumber of walks: 35820\taverage walk length: 8.5382\tbuild time: 19.5557\n",
            "building a node2vec model...\tnumber of walks: 35820\taverage walk length: 9.7997\tbuild time: 32.5327\n",
            "edges have mean weights 1.0 with std 0.0\n",
            "number of nodes: 3600\n",
            "number of edges: 12551\n",
            "building a DeepWalk model...\tnumber of walks: 36000\taverage walk length: 8.4938\tbuild time: 25.0922\n",
            "building a node2vec model...\tnumber of walks: 36000\taverage walk length: 9.6696\tbuild time: 48.8773\n",
            "DeepWalk: avg auc score: 0.7696\tstd: 0.0101\n",
            "node2vec: avg auc score: 0.8064\tstd: 0.0089\n"
          ]
        }
      ],
      "source": [
        "case(kfold=5, node_dim=10, num_walks=10, walk_length=10, p=0.5, q=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbeSsdlNjypE"
      },
      "source": [
        "With the help of p and q, the node2vec model can fit training data better. And you can have a try if you set p=q=1, the two models will return the same results."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "comp4332",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
